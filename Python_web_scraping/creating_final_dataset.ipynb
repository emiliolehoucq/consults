{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fde0c2a3",
   "metadata": {},
   "source": [
    "# Creating [CESNET-L](https://www.cesnet-l.net/) final dataset\n",
    "\n",
    "Emilio Lehoucq - 3/6/24\n",
    "\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc1b7671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe377ac",
   "metadata": {},
   "source": [
    "## Append data for all weekly compilations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8545d781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception with file 'data_compilation_june_2019_week_4.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_july_2020_week_3.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_june_2019_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_august_2015_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_may_2020_week_2.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_june_2023_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_november_2017_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_november_2020_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_may_2020_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_may_2017_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_february_2016_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_august_2018_week_1.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_january_2015_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_november_2018_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_july_2015_week_2.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_july_2018_week_1.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_may_2015_week_1.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_march_2024_week_1.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_may_2015_week_3.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_august_2020_week_4.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_july_2022_week_1.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_april_2015_week_2.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_november_2015_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_july_2018_week_3.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_august_2020_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_june_2016_week_4.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_december_2020_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_april_2018_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_may_2015_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_may_2022_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_april_2015_week_4.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_january_2020_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_april_2015_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_june_2016_week_2.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_may_2015_week_4.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_july_2021_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_july_2016_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_june_2015_week_1.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_october_2014_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_june_2015_week_2.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_december_2014_week_3.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_march_2015_week_3.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_april_2016_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_may_2021_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_may_2016_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_february_2017_week_1.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_may_2016_week_1.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_december_2019_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_june_2018_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_december_2019_week_4.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_september_2018_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_february_2020_week_2.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_april_2016_week_3.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_april_2016_week_2.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_december_2014_week_4.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_june_2015_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_july_2016_week_1.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_july_2023_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_january_2016_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_august_2021_week_2.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_june_2020_week_2.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_april_2023_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_july_2019_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_november_2019_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_december_2021_week_4.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_december_2016_week_4.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_june_2017_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_june_2020_week_4.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_august_2021_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_december_2016_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_december_2021_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_march_2020_week_5.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "Exception with file 'data_compilation_july_2019_week_3.csv'.\n",
      "Exception: No columns to parse from file.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Number of weekly compilations: 552\n",
      "Number of possibly empty files: 73\n",
      "Number of total rows: 2308\n",
      "Number of rows without data: 0\n",
      "Number of rows with data: 2308\n"
     ]
    }
   ],
   "source": [
    "# Get all csv files in current working directory\n",
    "csv_files = glob(\"*.csv\")\n",
    "\n",
    "# Read first file\n",
    "data_all_compilations = pd.read_csv(csv_files[0])\n",
    "\n",
    "# Variable to count number of files with errors in appending\n",
    "counter = 0\n",
    "\n",
    "# Iterate over the rest of the files appending them to the first\n",
    "for i in range(1, len(csv_files)):\n",
    "    try:\n",
    "        data_all_compilations = pd.concat([data_all_compilations, pd.read_csv(csv_files[i])], ignore_index = True)\n",
    "    except Exception as e:\n",
    "        counter += 1\n",
    "        print(f\"Exception with file '{csv_files[i]}'.\")\n",
    "        print(f'Exception: {e}.\\n')\n",
    "        pass\n",
    "\n",
    "# Number of weekly compilations\n",
    "print(f'\\n\\n\\nNumber of weekly compilations: {len(csv_files)}')\n",
    "\n",
    "# Number of possibly empty files\n",
    "print(f'Number of possibly empty files: {counter}')\n",
    "\n",
    "# Number of total rows\n",
    "count_rows = data_all_compilations.shape[0]\n",
    "print(f'Number of total rows: {count_rows}')\n",
    "\n",
    "# Number of rows without data (all NA)\n",
    "count_no_postings = data_all_compilations[data_all_compilations.iloc[:, 2:].isna().all(axis=1)].shape[0]\n",
    "print(f'Number of rows without data: {count_no_postings}')\n",
    "\n",
    "# Number of postings\n",
    "print(f'Number of rows with data: {count_rows - count_no_postings}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133e58b7",
   "metadata": {},
   "source": [
    "These exceptions happen because the CSVs are empty. I checked all the weekly compilations for those weeks and they didn't contain the search terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaaa56d",
   "metadata": {},
   "source": [
    "## Exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2305077b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where source code is different between plain text and html: 0\n",
      "Number of rows where soup object is different between plain text and html: 0\n",
      "Number of rows where extracted text is different between plain text and html: 0\n"
     ]
    }
   ],
   "source": [
    "# Columns with data of interest\n",
    "relevant_columns = data_all_compilations.columns[data_all_compilations.columns.str.startswith(('plain_', 'html_'))]\n",
    "\n",
    "# Dataframe only with rows without missing data on columns of interest\n",
    "df_no_na = data_all_compilations.dropna(subset = relevant_columns, how = 'any')\n",
    "\n",
    "print(f\"Number of rows where source code is different between plain text and html: {df_no_na[df_no_na['plain_text_message_source_code'] != df_no_na['html_message_source_code']].shape[0]}\")\n",
    "print(f\"Number of rows where soup object is different between plain text and html: {df_no_na[df_no_na['plain_text_message_soup'] != df_no_na['html_message_soup']].shape[0]}\")\n",
    "print(f\"Number of rows where extracted text is different between plain text and html: {df_no_na[df_no_na['plain_text_message_text'] != df_no_na['html_message_text']].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32379e33",
   "metadata": {},
   "source": [
    "Plain text and html data are the same.\n",
    "\n",
    "## Reshaping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "042b4917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing data on resulting dataframe: 0\n",
      "Dimensions of resulting dataframe: (2308, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_collection</th>\n",
       "      <th>week_compilation</th>\n",
       "      <th>source_code</th>\n",
       "      <th>soup</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-05 16:39:46</td>\n",
       "      <td>December 2018, Week 5</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;\\n&lt;title&gt;LISTSERV 16.5 - CESNET-L ...</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;\\n&lt;title&gt;LISTSERV 16.5 - CESNET-L ...</td>\n",
       "      <td>\\nLISTSERV 16.5 - CESNET-L Archives\\n\\n\\n\\n\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-06 04:08:28</td>\n",
       "      <td>January 2015, Week 1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;\\n&lt;title&gt;LISTSERV 16.5 - CESNET-L ...</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;\\n&lt;title&gt;LISTSERV 16.5 - CESNET-L ...</td>\n",
       "      <td>\\nLISTSERV 16.5 - CESNET-L Archives\\n\\n\\n\\n\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-06 04:09:02</td>\n",
       "      <td>January 2015, Week 1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;\\n&lt;title&gt;LISTSERV 16.5 - CESNET-L ...</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;\\n&lt;title&gt;LISTSERV 16.5 - CESNET-L ...</td>\n",
       "      <td>\\nLISTSERV 16.5 - CESNET-L Archives\\n\\n\\n\\n\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-06 04:09:36</td>\n",
       "      <td>January 2015, Week 1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;\\n&lt;title&gt;LISTSERV 16.5 - CESNET-L ...</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;\\n&lt;title&gt;LISTSERV 16.5 - CESNET-L ...</td>\n",
       "      <td>\\nLISTSERV 16.5 - CESNET-L Archives\\n\\n\\n\\n\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-05 04:50:14</td>\n",
       "      <td>January 2022, Week 1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;\\n&lt;title&gt;LISTSERV 16.5 - CESNET-L ...</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;\\n&lt;title&gt;LISTSERV 16.5 - CESNET-L ...</td>\n",
       "      <td>\\nLISTSERV 16.5 - CESNET-L Archives\\n\\n\\n\\n\\n\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp_collection       week_compilation  \\\n",
       "0  2024-03-05 16:39:46  December 2018, Week 5   \n",
       "1  2024-03-06 04:08:28   January 2015, Week 1   \n",
       "2  2024-03-06 04:09:02   January 2015, Week 1   \n",
       "3  2024-03-06 04:09:36   January 2015, Week 1   \n",
       "4  2024-03-05 04:50:14   January 2022, Week 1   \n",
       "\n",
       "                                         source_code  \\\n",
       "0  <html><head>\\n<title>LISTSERV 16.5 - CESNET-L ...   \n",
       "1  <html><head>\\n<title>LISTSERV 16.5 - CESNET-L ...   \n",
       "2  <html><head>\\n<title>LISTSERV 16.5 - CESNET-L ...   \n",
       "3  <html><head>\\n<title>LISTSERV 16.5 - CESNET-L ...   \n",
       "4  <html><head>\\n<title>LISTSERV 16.5 - CESNET-L ...   \n",
       "\n",
       "                                                soup  \\\n",
       "0  <html><head>\\n<title>LISTSERV 16.5 - CESNET-L ...   \n",
       "1  <html><head>\\n<title>LISTSERV 16.5 - CESNET-L ...   \n",
       "2  <html><head>\\n<title>LISTSERV 16.5 - CESNET-L ...   \n",
       "3  <html><head>\\n<title>LISTSERV 16.5 - CESNET-L ...   \n",
       "4  <html><head>\\n<title>LISTSERV 16.5 - CESNET-L ...   \n",
       "\n",
       "                                                text  \n",
       "0  \\nLISTSERV 16.5 - CESNET-L Archives\\n\\n\\n\\n\\n\\...  \n",
       "1  \\nLISTSERV 16.5 - CESNET-L Archives\\n\\n\\n\\n\\n\\...  \n",
       "2  \\nLISTSERV 16.5 - CESNET-L Archives\\n\\n\\n\\n\\n\\...  \n",
       "3  \\nLISTSERV 16.5 - CESNET-L Archives\\n\\n\\n\\n\\n\\...  \n",
       "4  \\nLISTSERV 16.5 - CESNET-L Archives\\n\\n\\n\\n\\n\\...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating new columns based on either html or plain text data\n",
    "data_all_compilations['source_code'] = data_all_compilations.apply(\n",
    "    lambda row: row['html_message_source_code'] if pd.isnull(row['plain_text_message_source_code']) else row['plain_text_message_source_code'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "data_all_compilations['soup'] = data_all_compilations.apply(\n",
    "    lambda row: row['html_message_soup'] if pd.isnull(row['plain_text_message_soup']) else row['plain_text_message_soup'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "data_all_compilations['text'] = data_all_compilations.apply(\n",
    "    lambda row: row['html_message_text'] if pd.isnull(row['plain_text_message_text']) else row['plain_text_message_text'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Deleting old columns\n",
    "data_all_compilations.drop(columns = relevant_columns, inplace = True)\n",
    "\n",
    "# Number of rows with missing data on resulting dataframe\n",
    "print(f\"Number of rows with missing data on resulting dataframe: {data_all_compilations[data_all_compilations.isnull().any(axis = 1)].shape[0]}\")\n",
    "\n",
    "# Dimensions of resulting dataframe\n",
    "print(f'Dimensions of resulting dataframe: {data_all_compilations.shape}')\n",
    "\n",
    "# What the resulting data looks like\n",
    "data_all_compilations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10902bd8",
   "metadata": {},
   "source": [
    "## Saving final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77cb30f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_compilations.to_csv('cesnet_data_march_6_2024.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
